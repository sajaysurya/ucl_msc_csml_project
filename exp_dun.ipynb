{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "experiment - semi-converging EM\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import agent\n",
    "import dungeon as fl\n",
    "import utils\n",
    "\n",
    "# pretify\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data structures to store the results\n",
    "'''\n",
    "log = pd.DataFrame(columns=['algorithm',\n",
    "                           'average-reward/time-step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "game details and parameters\n",
    "'''\n",
    "# make the game to get details\n",
    "game = fl.make_game()\n",
    "obs = game.its_showtime()\n",
    "\n",
    "# parameters\n",
    "num_experiments = 100\n",
    "world_param = fl.get_params()\n",
    "num_states = world_param['num_states']\n",
    "num_actions = world_param['num_actions']\n",
    "len_episodes = 100\n",
    "discount = 0.9\n",
    "# reward function\n",
    "reward = 10 * np.ones((num_states, num_actions))\n",
    "# update rewards (state, action) for movement into goal and traps\n",
    "reward[0, 3] = 0\n",
    "reward[1, 3] = 0\n",
    "reward[2, 3] = 20\n",
    "# start distribution - uniform (but there are 2 confusion states)\n",
    "start_dist = np.ones(num_states)\n",
    "start_dist[3] += 1\n",
    "start_dist /= np.sum(start_dist)\n",
    "\n",
    "# transition distribution (just alpha counts)\n",
    "alpha = np.zeros((num_states, num_states, num_actions))\n",
    "# go through all states\n",
    "# going north is useless\n",
    "alpha[0, 0, 2] = 1\n",
    "alpha[1, 1, 2] = 1\n",
    "alpha[2, 2, 2] = 1\n",
    "alpha[3, 3, 2] = 1\n",
    "# going south is useless if there is a wall\n",
    "alpha[3, 3, 3] = 1\n",
    "# going south has uniform distribution if there is no wall\n",
    "alpha[:, 0, 3] = 1\n",
    "alpha[:, 1, 3] = 1\n",
    "alpha[:, 2, 3] = 1\n",
    "# going left and right is useless, if next to a wall\n",
    "alpha[1, 1, 1] = 1\n",
    "alpha[0, 0, 0] = 1\n",
    "# from middle, going both left/right takes to confusion\n",
    "alpha[3, 2, 0] = 1\n",
    "alpha[3, 2, 1] = 1\n",
    "# from right end, going left takes to confusion\n",
    "alpha[3, 1, 0] = 1\n",
    "# from left end, going right takes to confusion\n",
    "alpha[3, 0, 1] = 1\n",
    "# from confusion it is confusing\n",
    "alpha[2, 3, 0] = 1\n",
    "alpha[0, 3, 0] = 1\n",
    "alpha[2, 3, 1] = 1\n",
    "alpha[1, 3, 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0385e67cbc0402a83e553c265a0cd49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "States:\t\t left, right, middle, confuse\n",
      "action left\t [0.   0.99 0.   0.17]\n",
      "action right\t [0.99 0.01 0.   0.82]\n",
      "action up\t [0.01 0.01 0.   0.  ]\n",
      "action down\t [0.   0.   1.   0.01]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Using EM\n",
    "'''\n",
    "# for every experiment\n",
    "for _ in tqdm(range(num_experiments)):\n",
    "    # reset total reward per episode count\n",
    "    total_reward = 0\n",
    "    # create agent\n",
    "    bond = agent.MLEM(num_actions,\n",
    "                      num_states,\n",
    "                      discount,\n",
    "                      len_episodes)\n",
    "    # set transition distribution\n",
    "    bond.alpha = np.copy(alpha)\n",
    "    bond.update_theta()\n",
    "    # set reward details\n",
    "    bond.reward = np.copy(reward)\n",
    "    # set start distribution\n",
    "    bond.start_dist = np.copy(start_dist)\n",
    "\n",
    "    # learn policy\n",
    "    bond.learn(niter=250)\n",
    "    # make game for evaluation\n",
    "    game = fl.make_game()\n",
    "    obs = game.its_showtime()\n",
    "    for _ in range(len_episodes):\n",
    "        action = bond.play(utils.get_dungeon_state(obs))\n",
    "        obs = game.play(action)\n",
    "        if not obs[1] is None:\n",
    "            total_reward += obs[1]        \n",
    "    # add average reward to log\n",
    "    log=log.append(pd.DataFrame(\n",
    "        {'algorithm': \"MDP-EM\",\n",
    "         'average-reward/time-step': total_reward/len_episodes},\n",
    "        index=[log.size+1]))\n",
    "    # quit game\n",
    "    game.play(5)\n",
    "\n",
    "# print final policy\n",
    "print(\"States:\\t\\t left, right, middle, confuse\")\n",
    "print(\"action left\\t\", np.round(bond.policy[0], 2))\n",
    "print(\"action right\\t\", np.round(bond.policy[1], 2))\n",
    "print(\"action up\\t\", np.round(bond.policy[2], 2))\n",
    "print(\"action down\\t\", np.round(bond.policy[3], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0add8529c841cf85559b13c1db6f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Policy:\t\t action (0=left, 1=right, 2=up, 3=down)\n",
      "state left\t 1\n",
      "state right\t 0\n",
      "state middle\t 3\n",
      "state conf\t 0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Using Policy Iteration\n",
    "'''\n",
    "# for every experiment\n",
    "for _ in tqdm(range(num_experiments)):\n",
    "    # reset total reward per episode count\n",
    "    total_reward = 0\n",
    "    # create agent\n",
    "    bond = agent.PoliQ(num_actions,\n",
    "                      num_states,\n",
    "                      discount,\n",
    "                      len_episodes)\n",
    "    # set transition distribution\n",
    "    bond.alpha = np.copy(alpha)\n",
    "    bond.update_theta()\n",
    "    # set reward details\n",
    "    bond.reward = np.copy(reward)\n",
    "    # set start distribution\n",
    "    bond.start_dist = np.copy(start_dist)\n",
    "    \n",
    "    # learn policy\n",
    "    bond.learn(niter=250)\n",
    "    # make game for evaluation\n",
    "    game = fl.make_game()\n",
    "    obs = game.its_showtime()\n",
    "    for _ in range(len_episodes):\n",
    "        action = bond.play(utils.get_dungeon_state(obs))\n",
    "        obs = game.play(action)\n",
    "        if not obs[1] is None:\n",
    "            total_reward += obs[1]        \n",
    "    # add average reward to log\n",
    "    log=log.append(pd.DataFrame(\n",
    "        {'algorithm': \"MDP-PI\",\n",
    "         'average-reward/time-step': total_reward/len_episodes},\n",
    "        index=[log.size+1]))\n",
    "    # quit game\n",
    "    game.play(5)\n",
    "    \n",
    "# print final policy\n",
    "print(\"Policy:\\t\\t action (0=left, 1=right, 2=up, 3=down)\")\n",
    "print(\"state left\\t\", np.round(bond.policy[0], 2))\n",
    "print(\"state right\\t\", np.round(bond.policy[1], 2))\n",
    "print(\"state middle\\t\", np.round(bond.policy[2], 2))\n",
    "print(\"state conf\\t\", np.round(bond.policy[3], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "save the reward values\n",
    "'''\n",
    "log.to_pickle(\"exp_dun.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x108 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "code for plotting a good graph\n",
    "'''\n",
    "sns.set(rc={'figure.figsize':(8,1.5)})\n",
    "sns.set_style('whitegrid')\n",
    "sns.barplot(y=\"algorithm\",\n",
    "              x=\"average-reward/time-step\",\n",
    "              data=log,\n",
    "              ci=90)\n",
    "plt.savefig('exp_dun_result.png', dpi=600, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
